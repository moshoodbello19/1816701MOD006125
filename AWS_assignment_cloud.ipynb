{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "import math\n",
    "\n",
    "#Initializing Spark Conf\n",
    "conf=SparkConf()\\\n",
    "        .setMaster(\"local[*]\")\\\n",
    "        .setAppName(\"WordCount\")\\\n",
    "        .setExecutorEnv(\"spark.executor.memory\",\"1g\")\\\n",
    "        .setExecutorEnv(\"spark.driver.memory\",\"1g\")\n",
    "\n",
    "#Creating Spark Session\n",
    "spark=SparkSession.builder\\\n",
    "        .config(conf=conf)\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark context\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.install_pypi_package(\"pandas==0.25.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.install_pypi_package(\"boto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text file path\n",
    "textfile=\"s3://assignmentbkt/sample-a.txt\"\n",
    "out_text= \"sample-a-out.txt\"\n",
    "out_file_header = \"              Output for Sample - a                  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing textfile as rdd\n",
    "word_rdd=sc.textFile(textfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove punc and lowercase\n",
    "def lower_clean_str(x):\n",
    "  punc='!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n",
    "  lowercased_str = x.lower()\n",
    "  for ch in punc:\n",
    "    lowercased_str = lowercased_str.replace(ch, ' ')\n",
    "  return lowercased_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtered RDD\n",
    "filtered_rdd = word_rdd.map(lower_clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Words By \" \"\n",
    "separatedword_rdd=filtered_rdd.flatMap(lambda word: word.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing white spaces and empty fields\n",
    "separatedword_rdd = separatedword_rdd.filter(lambda x:x!='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding values to each word\n",
    "word_with_value=separatedword_rdd.map(lambda  word:(word,1))\n",
    "total_words = word_with_value.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduces by key(word) \n",
    "word_with_value_red=word_with_value.reduceByKey(lambda x,y:(x+y)).sortByKey()\n",
    "distinct_word_count = word_with_value_red.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changeing key and value positions\n",
    "word_count=word_with_value_red.map(lambda x:(x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by Frequency\n",
    "wc_sort = word_count.sortByKey(False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Dataframe using above RDD\n",
    "word_count_rdd = spark.sparkContext.parallelize(wc_sort)\n",
    "columns = [\"Frequency\",\"Word\"]\n",
    "word_count_df = word_count_rdd.toDF(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Rank column\n",
    "wc = word_count_df.withColumn(\"rank\",row_number().over(Window.orderBy(monotonically_increasing_id())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Values in Datafeame\n",
    "wc_val = wc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Popular words\n",
    "print(\"Popular words\")\n",
    "import math\n",
    "\n",
    "\n",
    "popthreshold = math.ceil(wc_val * 5 /100)\n",
    "print(popthreshold)\n",
    "\n",
    "popularwords = wc.select('rank','Word','Frequency').filter(wc.rank <= popthreshold)\n",
    "popularwords.show()\n",
    "popularwordspd = popularwords.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Common words\n",
    "print(\"Common words\")\n",
    "\n",
    "lowerthreshold = math.floor(wc_val * 47.5 /100)\n",
    "upperthreshold = math.ceil(wc_val * 52.5 /100)\n",
    "print(lowerthreshold)\n",
    "print(upperthreshold)\n",
    "\n",
    "commonwords = wc.select('rank','Word','Frequency').filter((wc.rank >=  lowerthreshold) & (wc.rank <=  upperthreshold))\n",
    "\n",
    "commonwords.show()\n",
    "commonwordspd = commonwords.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Rare words\n",
    "print(\"Rare words\")\n",
    "\n",
    "\n",
    "rarethreshold = math.floor(wc_val * 95 /100)\n",
    "print(rarethreshold)\n",
    "\n",
    "rarewords = wc.select('rank','Word','Frequency').filter(wc.rank >= rarethreshold)\n",
    "\n",
    "rarewords.show()\n",
    "rarewordspd = rarewords.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Character count reduced by char\n",
    "char_counts_with_value_red = word_with_value.flatMap(lambda each: each[0]).map(lambda char: char).map(lambda c: (c, 1)).reduceByKey(lambda v1, v2: v1 + v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changeing key value position\n",
    "char_count=char_counts_with_value_red.map(lambda x:(x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by frequency\n",
    "cc_sort = char_count.sortByKey(False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating DF using RDD\n",
    "char_count_rdd = spark.sparkContext.parallelize(cc_sort)\n",
    "columns = [\"Frequency\",\"Letter\"]\n",
    "char_count_df = char_count_rdd.toDF(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding ranking column\n",
    "cc = char_count_df.withColumn(\"Rank\",row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "cc.show(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe Size\n",
    "cc_val = cc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Popular Letters\n",
    "print(\"Popular Letters\")\n",
    "\n",
    "\n",
    "popthresholdcc = math.ceil(cc_val * 5 /100)\n",
    "print(popthresholdcc)\n",
    "\n",
    "popularchars = cc.select('Rank','Letter','Frequency').filter(cc.Rank <= popthresholdcc)\n",
    "popularchars.show()\n",
    "popularcharspd = popularchars.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Common Letters\n",
    "print(\"Common Letters\")\n",
    "\n",
    "lowerthresholdcc = math.floor(cc_val * 47.5 /100)\n",
    "upperthresholdcc = math.ceil(cc_val * 52.5 /100)\n",
    "print(lowerthresholdcc)\n",
    "print(upperthresholdcc)\n",
    "\n",
    "commonchars = cc.select('Rank','Letter','Frequency').filter((cc.Rank >=  lowerthresholdcc) & (cc.Rank <=  upperthresholdcc))\n",
    "commonchars.show()\n",
    "commoncharspd = commonchars.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Rare Letters\n",
    "print(\"Rare words\")\n",
    "\n",
    "\n",
    "rarethresholdcc = math.floor(cc_val * 95 /100)\n",
    "print(rarethresholdcc)\n",
    "\n",
    "rareletters = cc.select('Rank','Letter','Frequency').filter(cc.Rank >= rarethresholdcc)\n",
    "rateletterspd = rareletters.toPandas()\n",
    "rareletters.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing into output file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "value = \"---------------------------------------------\\n\"+out_file_header+ \"\\n\"+\"---------------------------------------------\\n\\n\"+\"total number of words = \" + str(total_words)+\"\\n\"+\"total number of distinct words = \" + str(distinct_word_count)+\"\\n\"+\"popular_threshold_word = \" + str(popthreshold)+\"\\n\"+\"common_threshold_l_word = \" + str(lowerthreshold)+\"\\n\"+\"common_threshold_u_word = \" + str(upperthreshold)+\"\\n\"+\"rare_threshold_word = \" + str(rarethreshold)+\"\\n\"+\"---------------------------------------------\\n\\n\"+\"Popular words \\n\"+str(popularwordspd)+\"\\n\\n\"+\"Common words \\n\"+str(commonwordspd)+\"\\n\\n\"+\"Rare words \\n\"+str(rarewordspd)+\"\\n\\n\"+\"---------------------------------------------\\n\\n\"+\"total number of distinct letters = \" + str(cc_val)+\"\\n\"+\"popular_threshold_letters = \" + str(popthresholdcc)+\"\\n\"+\"common_threshold_l_letters = \" + str(lowerthresholdcc)+\"\\n\"+\"common_threshold_u_letters = \" + str(upperthresholdcc)+\"\\n\"+\"rare_threshold_letters = \" + str(rarethresholdcc)+\"\\n\"+\"---------------------------------------------\\n\\n\"+\"Popular Letters \\n\"+str(popularcharspd)+\"\\n\\n\"+\"Common Letters \\n\"+str(commoncharspd)+\"\\n\\n\"+\"Rare Letters \\n\"+str(rateletterspd)+\"\\n\\n\"\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "s3.put_object(Body=value, Bucket=\"assignmentbkt\", Key=out_text)\n",
    "print(\"Saved in S3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda (pyspark)",
   "language": "python",
   "name": "anaconda-pysparkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
