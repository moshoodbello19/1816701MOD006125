{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "#Initializing Spark Conf\n",
    "conf=SparkConf()\\\n",
    "        .setMaster(\"local[*]\")\\\n",
    "        .setAppName(\"WordCount\")\\\n",
    "        .setExecutorEnv(\"spark.executor.memory\",\"1g\")\\\n",
    "        .setExecutorEnv(\"spark.driver.memory\",\"1g\")\n",
    "\n",
    "#Creating Spark Session\n",
    "spark=SparkSession.builder\\\n",
    "        .config(conf=conf)\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark context\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text file path\n",
    "textfile=\"/opt/awsAssignment/sample-a.txt\"\n",
    "out_text= \"/opt/awsAssignment/sample-a-out.txt\"\n",
    "out_file_header = \"              Output for Sample - a                  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing textfile as rdd\n",
    "word_rdd=sc.textFile(textfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove punc and lowercase\n",
    "def lower_clean_str(x):\n",
    "  punc='!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~1 2 3 4 5 6 7 8 9 0 -'\n",
    "  lowercased_str = x.lower()\n",
    "  for ch in punc:\n",
    "    lowercased_str = lowercased_str.replace(ch, ' ')\n",
    "  return lowercased_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtered RDD\n",
    "filtered_rdd = word_rdd.map(lower_clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Words By \" \"\n",
    "separatedword_rdd=filtered_rdd.flatMap(lambda word: word.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing white spaces and empty fields\n",
    "separatedword_rdd = separatedword_rdd.filter(lambda x:x!='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding values to each word\n",
    "word_with_value=separatedword_rdd.map(lambda  word:(word,1))\n",
    "total_words = word_with_value.count()\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduces by key(word) \n",
    "word_with_value_red=word_with_value.reduceByKey(lambda x,y:(x+y)).sortByKey()\n",
    "distinct_word_count = word_with_value_red.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changeing key and value positions\n",
    "word_count=word_with_value_red.map(lambda x:(x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by Frequency\n",
    "wc_sort = word_count.sortByKey(False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Dataframe using above RDD\n",
    "word_count_rdd = spark.sparkContext.parallelize(wc_sort)\n",
    "columns = [\"Frequency\",\"Word\"]\n",
    "word_count_df = word_count_rdd.toDF(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Rank column\n",
    "wc = word_count_df.withColumn(\"rank\",row_number().over(Window.orderBy(monotonically_increasing_id())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----+\n",
      "|Frequency|       Word|rank|\n",
      "+---------+-----------+----+\n",
      "|        3|      spark|   1|\n",
      "|        3|        the|   2|\n",
      "|        2|         an|   3|\n",
      "|        2|     apache|   4|\n",
      "|        1|     amplab|   5|\n",
      "|        1|        and|   6|\n",
      "|        1|         at|   7|\n",
      "|        1|   berkeley|   8|\n",
      "|        1| california|   9|\n",
      "|        1|    cluster|  10|\n",
      "|        1|   clusters|  11|\n",
      "|        1|   codebase|  12|\n",
      "|        1|  computing|  13|\n",
      "|        1|       data|  14|\n",
      "|        1|  developed|  15|\n",
      "|        1|distributed|  16|\n",
      "|        1|    donated|  17|\n",
      "|        1|     entire|  18|\n",
      "|        1|      fault|  19|\n",
      "|        1|        for|  20|\n",
      "|        1| foundation|  21|\n",
      "|        1|  framework|  22|\n",
      "|        1|    general|  23|\n",
      "|        1|        has|  24|\n",
      "|        1|   implicit|  25|\n",
      "|        1|  interface|  26|\n",
      "|        1|         is|  27|\n",
      "|        1|         it|  28|\n",
      "|        1|      later|  29|\n",
      "|        1| maintained|  30|\n",
      "|        1|         of|  31|\n",
      "|        1|       open|  32|\n",
      "|        1| originally|  33|\n",
      "|        1|parallelism|  34|\n",
      "|        1|programming|  35|\n",
      "|        1|   provides|  36|\n",
      "|        1|    purpose|  37|\n",
      "|        1|          s|  38|\n",
      "|        1|      since|  39|\n",
      "|        1|   software|  40|\n",
      "|        1|     source|  41|\n",
      "|        1|         to|  42|\n",
      "|        1|  tolerance|  43|\n",
      "|        1| university|  44|\n",
      "|        1|        was|  45|\n",
      "|        1|      which|  46|\n",
      "|        1|       with|  47|\n",
      "+---------+-----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wc.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Values in Datafeame\n",
    "wc_val = wc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular words\n",
      "3\n",
      "+----+-----+---------+\n",
      "|rank| Word|Frequency|\n",
      "+----+-----+---------+\n",
      "|   1|spark|        3|\n",
      "|   2|  the|        3|\n",
      "|   3|   an|        2|\n",
      "+----+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating Popular words\n",
    "print(\"Popular words\")\n",
    "import math\n",
    "\n",
    "\n",
    "popthreshold = math.ceil(wc_val * 5 /100)\n",
    "print(popthreshold)\n",
    "\n",
    "popularwords = wc.select('rank','Word','Frequency').filter(wc.rank <= popthreshold)\n",
    "popularwords.show()\n",
    "popularwordspd = popularwords.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common words\n",
      "22\n",
      "25\n",
      "+----+---------+---------+\n",
      "|rank|     Word|Frequency|\n",
      "+----+---------+---------+\n",
      "|  22|framework|        1|\n",
      "|  23|  general|        1|\n",
      "|  24|      has|        1|\n",
      "|  25| implicit|        1|\n",
      "+----+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating Common words\n",
    "print(\"Common words\")\n",
    "\n",
    "lowerthreshold = math.floor(wc_val * 47.5 /100)\n",
    "upperthreshold = math.ceil(wc_val * 52.5 /100)\n",
    "print(lowerthreshold)\n",
    "print(upperthreshold)\n",
    "\n",
    "commonwords = wc.select('rank','Word','Frequency').filter((wc.rank >=  lowerthreshold) & (wc.rank <=  upperthreshold))\n",
    "\n",
    "commonwords.show()\n",
    "commonwordspd = commonwords.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare words\n",
      "44\n",
      "+----+----------+---------+\n",
      "|rank|      Word|Frequency|\n",
      "+----+----------+---------+\n",
      "|  44|university|        1|\n",
      "|  45|       was|        1|\n",
      "|  46|     which|        1|\n",
      "|  47|      with|        1|\n",
      "+----+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating Rare words\n",
    "print(\"Rare words\")\n",
    "\n",
    "\n",
    "rarethreshold = math.floor(wc_val * 95 /100)\n",
    "print(rarethreshold)\n",
    "\n",
    "rarewords = wc.select('rank','Word','Frequency').filter(wc.rank >= rarethreshold)\n",
    "\n",
    "rarewords.show()\n",
    "rarewordspd = rarewords.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Letters \n",
    "char_counts_with_value_red = word_with_value.flatMap(lambda each: each[0]).map(lambda char: char).map(lambda c: (c, 1))\n",
    "char_counts_with_value_red.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Character count reduced by char\n",
    "char_counts_with_value_red = word_with_value.flatMap(lambda each: each[0]).map(lambda char: char)\\\n",
    "    .map(lambda c: (c, 1)).reduceByKey(lambda v1, v2: v1 + v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changeing key value position\n",
    "char_count=char_counts_with_value_red.map(lambda x:(x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by frequency\n",
    "cc_sort = char_count.sortByKey(False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating DF using RDD\n",
    "char_count_rdd = spark.sparkContext.parallelize(cc_sort)\n",
    "columns = [\"Frequency\",\"Letter\"]\n",
    "char_count_df = char_count_rdd.toDF(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----+\n",
      "|Frequency|Letter|Rank|\n",
      "+---------+------+----+\n",
      "|       36|     e|   1|\n",
      "|       35|     a|   2|\n",
      "|       25|     r|   3|\n",
      "|       25|     i|   4|\n",
      "|       24|     t|   5|\n",
      "|       19|     s|   6|\n",
      "|       19|     n|   7|\n",
      "|       19|     o|   8|\n",
      "|       16|     l|   9|\n",
      "|       15|     p|  10|\n",
      "|       13|     c|  11|\n",
      "|       12|     d|  12|\n",
      "|        9|     h|  13|\n",
      "|        9|     u|  14|\n",
      "|        8|     m|  15|\n",
      "|        8|     f|  16|\n",
      "|        5|     g|  17|\n",
      "|        5|     k|  18|\n",
      "|        5|     w|  19|\n",
      "|        4|     b|  20|\n",
      "|        3|     y|  21|\n",
      "|        3|     v|  22|\n",
      "+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adding ranking column\n",
    "cc = char_count_df.withColumn(\"Rank\",row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "cc.show(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe Size\n",
    "cc_val = cc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular Letters\n",
      "2\n",
      "+----+------+---------+\n",
      "|Rank|Letter|Frequency|\n",
      "+----+------+---------+\n",
      "|   1|     e|       36|\n",
      "|   2|     a|       35|\n",
      "+----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating Popular Letters\n",
    "print(\"Popular Letters\")\n",
    "\n",
    "\n",
    "popthresholdcc = math.ceil(cc_val * 5 /100)\n",
    "print(popthresholdcc)\n",
    "\n",
    "popularchars = cc.select('Rank','Letter','Frequency').filter(cc.Rank <= popthresholdcc)\n",
    "popularchars.show()\n",
    "popularcharspd = popularchars.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Letters\n",
      "10\n",
      "12\n",
      "+----+------+---------+\n",
      "|Rank|Letter|Frequency|\n",
      "+----+------+---------+\n",
      "|  10|     p|       15|\n",
      "|  11|     c|       13|\n",
      "|  12|     d|       12|\n",
      "+----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating Common Letters\n",
    "print(\"Common Letters\")\n",
    "\n",
    "lowerthresholdcc = math.floor(cc_val * 47.5 /100)\n",
    "upperthresholdcc = math.ceil(cc_val * 52.5 /100)\n",
    "print(lowerthresholdcc)\n",
    "print(upperthresholdcc)\n",
    "\n",
    "commonchars = cc.select('Rank','Letter','Frequency').filter((cc.Rank >=  lowerthresholdcc) & (cc.Rank <=  upperthresholdcc))\n",
    "commonchars.show()\n",
    "commoncharspd = commonchars.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare words\n",
      "20\n",
      "+----+------+---------+\n",
      "|Rank|Letter|Frequency|\n",
      "+----+------+---------+\n",
      "|  20|     b|        4|\n",
      "|  21|     y|        3|\n",
      "|  22|     v|        3|\n",
      "+----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating Rare Letters\n",
    "print(\"Rare words\")\n",
    "\n",
    "\n",
    "rarethresholdcc = math.floor(cc_val * 95 /100)\n",
    "print(rarethresholdcc)\n",
    "\n",
    "rareletters = cc.select('Rank','Letter','Frequency').filter(cc.Rank >= rarethresholdcc)\n",
    "rateletterspd = rareletters.toPandas()\n",
    "rareletters.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing into output file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of words=2186595\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of words=\" + str(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Writing Complete\n"
     ]
    }
   ],
   "source": [
    "f = open(out_text, \"a\")\n",
    "f.write(\"---------------------------------------------\\n\")\n",
    "f.write(out_file_header+ \"\\n\")\n",
    "f.write(\"---------------------------------------------\\n\\n\")\n",
    "f.write(\"total number of words = \" + str(total_words)+\"\\n\")\n",
    "f.write(\"total number of distinct words = \" + str(distinct_word_count)+\"\\n\")\n",
    "f.write(\"popular_threshold_word = \" + str(popthreshold)+\"\\n\")\n",
    "f.write(\"common_threshold_l_word = \" + str(lowerthreshold)+\"\\n\")\n",
    "f.write(\"common_threshold_u_word = \" + str(upperthreshold)+\"\\n\")\n",
    "f.write(\"rare_threshold_word = \" + str(rarethreshold)+\"\\n\")\n",
    "f.write(\"---------------------------------------------\\n\\n\")\n",
    "\n",
    "f.write(\"Popular words \\n\")\n",
    "f.write(str(popularwordspd))\n",
    "f.write(\"\\n\\n\")\n",
    "\n",
    "f.write(\"Common words \\n\")\n",
    "f.write(str(commonwordspd))\n",
    "f.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "f.write(\"Rare words \\n\")\n",
    "f.write(str(rarewordspd))\n",
    "f.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "f.write(\"---------------------------------------------\\n\\n\")\n",
    "f.write(\"total number of distinct letters = \" + str(cc_val)+\"\\n\")\n",
    "f.write(\"popular_threshold_letters = \" + str(popthresholdcc)+\"\\n\")\n",
    "f.write(\"common_threshold_l_letters = \" + str(lowerthresholdcc)+\"\\n\")\n",
    "f.write(\"common_threshold_u_letters = \" + str(upperthresholdcc)+\"\\n\")\n",
    "f.write(\"rare_threshold_letters = \" + str(rarethresholdcc)+\"\\n\")\n",
    "f.write(\"---------------------------------------------\\n\\n\")\n",
    "\n",
    "f.write(\"Popular Letters \\n\")\n",
    "f.write(str(popularcharspd))\n",
    "f.write(\"\\n\\n\")\n",
    "\n",
    "f.write(\"Common Letters \\n\")\n",
    "f.write(str(commoncharspd))\n",
    "f.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "f.write(\"Rare Letters \\n\")\n",
    "f.write(str(rateletterspd))\n",
    "f.write(\"\\n\\n\")\n",
    "\n",
    "f.close()\n",
    "\n",
    "print(\"File Writing Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda (pyspark)",
   "language": "python",
   "name": "anaconda-pysparkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
